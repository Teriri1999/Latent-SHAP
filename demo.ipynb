{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02c6b87-213e-4dbc-a115-8832ce1860f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from captum.attr import KernelShap\n",
    "import cv2\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from model import Generator\n",
    "from combine_model import AlexNetMNIST, CombinedModel\n",
    "from utils import make_image, generate_heatmap, generate_color_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1151ac5-8a8b-4242-9e47-00e73afadf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1f1da3-a963-4e81-92ec-ba5378b8f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"E:/Latent SHAP github/test_sample/image/test.jpg\"\n",
    "latent_path = \"test_sample/latent_code/test.pth\"\n",
    "sample = torch.load(latent_path)\n",
    "sample.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb476ef3-2e1e-4939-9f40-17885b336cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet = AlexNetMNIST()\n",
    "alexnet.to(device)\n",
    "model_path = 'checkpoint/alexnet/mnist_model.pth'\n",
    "alexnet.load_state_dict(torch.load(model_path, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38261f47-cca1-45fe-9833-5bd7e563556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "image = Image.open(img_path)\n",
    "image_tensor = transform(image).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c57ed3-8c52-41c7-8721-624981ce9beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob tensor([[ 20.6294, -29.4004, -23.2256, -17.8429, -19.1856, -20.5424,  -5.3435,\n",
      "         -29.6415, -20.3315,  -8.3095]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "alexnet.eval()\n",
    "output = alexnet(image_tensor)\n",
    "target = int(output.argmax().detach().cpu().numpy())\n",
    "print('Prob', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42377758-92b6-4934-9c4c-e08da25e9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_path = \"GAN_checkpoint/pretrained.pt\"\n",
    "g_ema = Generator(32, 256, 8)\n",
    "g_ema.load_state_dict(torch.load(gan_path)[\"g_ema\"], strict=False)\n",
    "g_ema.eval()\n",
    "g_ema = g_ema.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16e71ce-c189-438d-ac48-ead8d017fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = CombinedModel(g_ema, alexnet, transform)\n",
    "combined_model = combined_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ede34d-759c-4425-b70a-b9aef1de2436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3eceb1fdaf0407da856cb6cf5b61087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Kernel Shap attribution:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1.4569950103759766 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ks = KernelShap(combined_model)\n",
    "n_samples = 100\n",
    "attributions = ks.attribute(sample, target=target, n_samples=n_samples, show_progress=True)\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01e5ad2c-21e8-495c-95a4-64eddb6106e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [01:43<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 17, 17]) torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mapping = torch.zeros([256, 3, 32, 32])\n",
    "img_gen, _ = g_ema([sample], input_is_latent=False, noise=None, randomize_noise=False)\n",
    "\n",
    "for j in tqdm(range(32)):\n",
    "    for i in range(3):\n",
    "        for k in range(32):\n",
    "            pixel_value = img_gen[0, i, j, k].mean()\n",
    "            pixel_value.backward(retain_graph=True)\n",
    "            for l in range(256):\n",
    "                mapping[l, i, j, k] = sample.grad[0][l].clone()\n",
    "            sample.grad.zero_()\n",
    "\n",
    "image_np = np.array(image)\n",
    "image_tensor = image_np / 255\n",
    "image_tensor = np.transpose(image_tensor, (2, 0, 1))\n",
    "image_tensor = np.expand_dims(image_tensor, axis=0)\n",
    "\n",
    "threshold = 1\n",
    "\n",
    "image_tensor = torch.from_numpy(image_tensor)\n",
    "\n",
    "above_threshold = mapping > threshold\n",
    "\n",
    "pool_radius = 1\n",
    "kernel_size = 1 * pool_radius + 1\n",
    "max_pool = torch.nn.MaxPool2d(kernel_size, padding=pool_radius)\n",
    "activated_map = max_pool(above_threshold.float())\n",
    "print(activated_map.shape, image_tensor.shape)\n",
    "activated_map = F.interpolate(activated_map, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "\n",
    "# result = activated_map.float() * image_tensor\n",
    "result = activated_map.float()\n",
    "map = result.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24e8b2b9-9396-41c2-add4-5f95a4083028",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions = attributions.view(256, 1, 1, 1)\n",
    "attributions[attributions < 0] = 0\n",
    "\n",
    "fusion_shap = attributions * map\n",
    "fusion_max = fusion_shap.max()\n",
    "fusion_min = fusion_shap.min()\n",
    "fusion_norm = (fusion_shap - fusion_min) / (fusion_max - fusion_min)\n",
    "Shapley = fusion_norm.mean(dim=0)\n",
    "img_ar = make_image(Shapley.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce0b1e18-d8e6-42dd-99d4-b82298709785",
   "metadata": {},
   "outputs": [],
   "source": [
    "backgroud_set = torchvision.datasets.ImageFolder(root=\"background\", transform=transform)\n",
    "background_loader = torch.utils.data.DataLoader(backgroud_set, batch_size=300,shuffle=True)\n",
    "classes = backgroud_set.classes\n",
    "\n",
    "background_dataiter = iter(background_loader)\n",
    "b_images, b_labels = next(background_dataiter)\n",
    "\n",
    "b_images = b_images.to((device))\n",
    "b_labels = b_labels.to((device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9216425c-b89e-42de-9e6b-2e76949fca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 2.6126177310943604 seconds\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(img_path)\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0)\n",
    "image = image.to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "alexnet.eval()\n",
    "\n",
    "e = shap.GradientExplainer(alexnet, b_images)\n",
    "shap_values = e.shap_values(image)\n",
    "shap_numpy_g = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "931ec9ee-925d-416a-9aff-e9a53cbcb219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 3.903348922729492 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "alexnet.eval()\n",
    "e = shap.DeepExplainer(alexnet, b_images)\n",
    "shap_values = e.shap_values(image)\n",
    "shap_numpy_d = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b055d10-dcca-497f-8ce1-4eb2752fd354",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = target\n",
    "gradient_shap = shap_numpy_g[target_label][0]\n",
    "gradient_shap = np.sum(gradient_shap, axis=2)\n",
    "gradient_shap = np.maximum(gradient_shap, 0)\n",
    "gradient_shap = cv2.resize(gradient_shap, (28, 28))\n",
    "\n",
    "deep_shap = shap_numpy_d[target_label][0]\n",
    "deep_shap = np.sum(deep_shap, axis=2)\n",
    "deep_shap = np.maximum(deep_shap, 0)\n",
    "deep_shap = cv2.resize(deep_shap, (28, 28))\n",
    "\n",
    "latent_shap = img_ar[0, :, :, :]\n",
    "latent_shap = np.mean(latent_shap, 2)\n",
    "latent_shap = np.maximum(latent_shap, 0)\n",
    "latent_shap = cv2.resize(latent_shap, (28, 28))\n",
    "# latent_shap = 255 * (fusion_map - fusion_map.min()) / (fusion_map.max() - fusion_map.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0515990-926d-46a8-8b87-badbda5d15ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image_np)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(gradient_shap)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(deep_shap)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(latent_shap)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8976b47-71dc-4d58-87db-686538cce956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
