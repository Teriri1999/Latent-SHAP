{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02c6b87-213e-4dbc-a115-8832ce1860f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from captum.attr import KernelShap\n",
    "import cv2\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "from model import Generator\n",
    "from combine_model import AlexNetMNIST, CombinedModel\n",
    "from utils import make_image, generate_heatmap, generate_color_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1151ac5-8a8b-4242-9e47-00e73afadf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1f1da3-a963-4e81-92ec-ba5378b8f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"E:/Latent SHAP github/test_sample/image/test.jpg\"\n",
    "latent_path = \"test_sample/latent_code/test.pth\"\n",
    "sample = torch.load(latent_path)\n",
    "sample.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb476ef3-2e1e-4939-9f40-17885b336cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet = AlexNetMNIST()\n",
    "alexnet.to(device)\n",
    "model_path = 'checkpoint/alexnet/mnist_model.pth'\n",
    "alexnet.load_state_dict(torch.load(model_path, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38261f47-cca1-45fe-9833-5bd7e563556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "image = Image.open(img_path)\n",
    "image_tensor = transform(image).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c57ed3-8c52-41c7-8721-624981ce9beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob tensor([[ 20.6294, -29.4004, -23.2256, -17.8429, -19.1856, -20.5424,  -5.3435,\n",
      "         -29.6415, -20.3315,  -8.3095]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "alexnet.eval()\n",
    "output = alexnet(image_tensor)\n",
    "target = int(output.argmax().detach().cpu().numpy())\n",
    "print('Prob', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42377758-92b6-4934-9c4c-e08da25e9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_path = \"GAN_checkpoint/pretrained.pt\"\n",
    "g_ema = Generator(32, 256, 8)\n",
    "g_ema.load_state_dict(torch.load(gan_path)[\"g_ema\"], strict=False)\n",
    "g_ema.eval()\n",
    "g_ema = g_ema.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16e71ce-c189-438d-ac48-ead8d017fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = CombinedModel(g_ema, alexnet, transform)\n",
    "combined_model = combined_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ede34d-759c-4425-b70a-b9aef1de2436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719a6a51b6fb4e54828e1649cc9db4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Kernel Shap attribution:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ks = KernelShap(combined_model)\n",
    "n_samples = 200\n",
    "attributions = ks.attribute(sample, target=target, n_samples=n_samples, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01e5ad2c-21e8-495c-95a4-64eddb6106e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 17, 17]) torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "mapping = torch.zeros([256, 3, 32, 32])\n",
    "img_gen, _ = g_ema([sample], input_is_latent=False, noise=None, randomize_noise=False)\n",
    "\n",
    "for j in range(32):\n",
    "    for i in range(3):\n",
    "        for k in range(32):\n",
    "            pixel_value = img_gen[0, i, j, k].mean()\n",
    "            pixel_value.backward(retain_graph=True)\n",
    "            for l in range(256):\n",
    "                mapping[l, i, j, k] = sample.grad[0][l].clone()\n",
    "            sample.grad.zero_()\n",
    "\n",
    "image_np = np.array(image)\n",
    "image_tensor = image_np / 255\n",
    "image_tensor = np.transpose(image_tensor, (2, 0, 1))\n",
    "image_tensor = np.expand_dims(image_tensor, axis=0)\n",
    "\n",
    "threshold = 1\n",
    "\n",
    "image_tensor = torch.from_numpy(image_tensor)\n",
    "\n",
    "above_threshold = mapping > threshold\n",
    "\n",
    "pool_radius = 1\n",
    "kernel_size = 1 * pool_radius + 1\n",
    "max_pool = torch.nn.MaxPool2d(kernel_size, padding=pool_radius)\n",
    "activated_map = max_pool(above_threshold.float())\n",
    "print(activated_map.shape, image_tensor.shape)\n",
    "activated_map = F.interpolate(activated_map, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "\n",
    "result = activated_map.float()\n",
    "map = result.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24e8b2b9-9396-41c2-add4-5f95a4083028",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions = attributions.view(256, 1, 1, 1)\n",
    "attributions[attributions < 0] = 0\n",
    "\n",
    "fusion_shap = attributions * map\n",
    "fusion_max = fusion_shap.max()\n",
    "fusion_min = fusion_shap.min()\n",
    "fusion_norm = (fusion_shap - fusion_min) / (fusion_max - fusion_min)\n",
    "Shapley = fusion_norm.mean(dim=0)\n",
    "img_ar = make_image(Shapley.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce0b1e18-d8e6-42dd-99d4-b82298709785",
   "metadata": {},
   "outputs": [],
   "source": [
    "backgroud_set = torchvision.datasets.ImageFolder(root=\"background\", transform=transform)\n",
    "background_loader = torch.utils.data.DataLoader(backgroud_set, batch_size=300,shuffle=True)\n",
    "classes = backgroud_set.classes\n",
    "\n",
    "background_dataiter = iter(background_loader)\n",
    "b_images, b_labels = next(background_dataiter)\n",
    "\n",
    "b_images = b_images.to((device))\n",
    "b_labels = b_labels.to((device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9216425c-b89e-42de-9e6b-2e76949fca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(img_path)\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0)\n",
    "image = image.to(device)\n",
    "\n",
    "alexnet.eval()\n",
    "\n",
    "e = shap.GradientExplainer(alexnet, b_images)\n",
    "shap_values = e.shap_values(image)\n",
    "shap_numpy_g = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "931ec9ee-925d-416a-9aff-e9a53cbcb219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    }
   ],
   "source": [
    "alexnet.eval()\n",
    "e = shap.DeepExplainer(alexnet, b_images)\n",
    "shap_values = e.shap_values(image)\n",
    "shap_numpy_d = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b055d10-dcca-497f-8ce1-4eb2752fd354",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = target\n",
    "gradient_shap = shap_numpy_g[target_label][0]\n",
    "gradient_shap = np.sum(gradient_shap, axis=2)\n",
    "gradient_shap = np.maximum(gradient_shap, 0)\n",
    "gradient_shap = cv2.resize(gradient_shap, (28, 28))\n",
    "\n",
    "deep_shap = shap_numpy_d[target_label][0]\n",
    "deep_shap = np.sum(deep_shap, axis=2)\n",
    "deep_shap = np.maximum(deep_shap, 0)\n",
    "deep_shap = cv2.resize(deep_shap, (28, 28))\n",
    "\n",
    "latent_shap = img_ar[0, :, :, :]\n",
    "latent_shap = np.mean(latent_shap, 2)\n",
    "latent_shap = np.maximum(latent_shap, 0)\n",
    "latent_shap = cv2.resize(latent_shap, (28, 28))\n",
    "# latent_shap = 255 * (fusion_map - fusion_map.min()) / (fusion_map.max() - fusion_map.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0515990-926d-46a8-8b87-badbda5d15ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image_np)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(gradient_shap)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(deep_shap)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(latent_shap)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8976b47-71dc-4d58-87db-686538cce956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
